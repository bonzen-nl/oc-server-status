# oc-server-status

**Unified Server & Token Monitoring for OpenClaw**

Realtime monitoring van server gezondheid, token verbruik (alle providers), en kostenanalyse. Alle informatie in Ã‰Ã‰N geÃ¯ntegreerd rapport.

## Features

### ðŸ“Š Server Metrics
- **RAM/Swap:** Realtime gebruik in GB en percentages
- **CPU:** Load average (1/5/15 min), core count
- **Disk:** Free space, total, percentage used
- **Temperature:** CPU temp (macOS via system_profiler)
- **Services:** Ollama models count/memory, ChromaDB doc count

### ðŸ’° Token Telemetry (Unified)
- **Alle providers:** Anthropic, OpenAI, Google Gemini, Ollama
- **Per provider:** Totaal tokens, kosten (EUR), aantal calls
- **Top models:** Top 10 modellen per kosten (alle providers)
- **Budget tracking:** Monthly limits, spent/remaining

### ðŸ“ˆ Token Timeline Analysis
- **Dagelijks:** Per-model breakdown (vandaag, gisteren, eergisteren)
- **Wekelijks:** Trends per week per model
- **Maandelijks:** Vergelijking vorige maanden per model
- **Efficiency:** Kosten/token, tokens/call gemiddeld

### âš™ï¸ Intelligent Recommendations
- RAM pressure detection & actions
- Swap usage warnings
- Budget burn rate alerts
- Service availability checks

## Installation

```bash
# Clone the repo
git clone https://github.com/bonzen-nl/oc-server-status.git
cd oc-server-status

# Setup Python venv
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

## Configuration

```bash
# Copy example config
cp config/server_status.json.example config/server_status.json

# Edit with your settings
nano config/server_status.json
```

**Configuration keys:**
- `monitoring.report_interval_hours` â€” Interval tussen rapporten
- `monitoring.critical_ram_threshold_percent` â€” Critical RAM threshold
- `telegram.enabled` â€” Telegram notifications aan/uit
- `telegram.chat_id` â€” Telegram chat ID voor alerts
- `chromadb_path` â€” Path naar ChromaDB index
- `budget.monthly_limit_eur` â€” Monthly token budget (EUR)
- `ollama_base_url` â€” Ollama API endpoint
- `openai_api_key` â€” OpenAI API key (optioneel)
- `anthropic_api_key` â€” Anthropic API key (optioneel)
- `google_api_key` â€” Google Gemini API key (optioneel)

## Usage

### Generate Report (Text)
```bash
python3 scripts/server_status.py --now
```

Output:
```
ðŸ“Š OPENÐ¡LAW SERVER STATUS â€” 2026-02-27 23:05 CET
================================================================================

ðŸŸ¢ HEALTHY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RAM:  25.6% (  5.5GB /  24.0GB)
CPU:    1.87 load (4 cores)
Swap:   68.0% (  2.7GB /   4.0GB)
Disk:    6.9% (155.4GB free)

SERVICES:
  Ollama:    2 models (4.0GB)
  ChromaDB:  99 docs (2.0MB)

================================================================================
ðŸ’° TOKEN TELEMETRIE â€” 2026-02
================================================================================

ðŸ“Š TOTAAL:
  Tokens:                130
  Kosten:    â‚¬          0.00

ðŸ”Œ PER AANBIEDER (Anthropic, OpenAI, Google, Ollama):
  ollama          | â‚¬    0.00 |        130 tokens

ðŸ† TOP MODELLEN (alle providers):
   1. ollama      /mistral                        â‚¬    0.00

ðŸ’³ BUDGET:
  Monthly:   â‚¬    100.00
  Spent:     â‚¬      0.00  (  0.0%)
  Remaining: â‚¬    100.00
  âœ… Gezond

======================================================================
ðŸ“ˆ TOKEN VERBRUIK PER MODEL â€” Dag / Week / Maand
======================================================================

ðŸ“… DAGELIJKS (meest recent):

  2026-02-27:
    ollama/mistral                      |      130 tokens | â‚¬0.00

ðŸ“Š WEKELIJKS:

  Week 2026-W08:
    ollama/mistral                      |      130 tokens | â‚¬0.00 (1d)

ðŸ“ˆ MAANDELIJKS (trend):

  ollama/mistral:
    2026-02:      130 tokens | â‚¬0.00

======================================================================

================================================================================
âš™ï¸  AANBEVELINGEN:
  âœ… RAM gezond

================================================================================
```

### Generate Report (JSON)
```bash
python3 scripts/server_status.py --now --format json
```

Output: Complete JSON with metrics, tokens, timeline for automation.

### Scheduled Reports (LaunchAgent / Cron)
```bash
# Every 6 hours (or custom interval)
# Writes to /tmp/openclaw_messages/ for heartbeat delivery
python3 /path/to/oc-server-status/scripts/server_status.py --now
```

## Project Structure

```
oc-server-status/
â”œâ”€â”€ README.md                           # Dit bestand
â”œâ”€â”€ LICENSE                             # MIT
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ server_status.json.example      # Configuration template
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ server_status.py                # Main unified report generator
â”‚
â””â”€â”€ lib/
    â”œâ”€â”€ metrics_collector.py            # System metrics (RAM, CPU, Disk, etc)
    â”œâ”€â”€ token_telemetry.py              # Token tracking + timeline analysis
    â””â”€â”€ __init__.py
```

## Integrations

### Telegram Notifications
Automatic alerts when:
- RAM > 90% (critical)
- Swap > 85% (soft cleanup trigger)
- Monthly budget > 75% spent
- Server errors detected

### Ollama Integration
- Auto-detect running models
- Memory tracking per model
- Model unload on RAM pressure

### ChromaDB Integration
- Document count monitoring
- Database size tracking
- Integrity checks

### Multi-Provider Token Tracking
Automatically aggregates token usage from:
- **Anthropic:** Claude models (Haiku, Sonnet, etc)
- **OpenAI:** GPT models
- **Google:** Gemini models
- **Ollama:** Local models (Mistral, Llama, etc)

## Architecture

### metrics_collector.py
Collects system metrics via psutil & macOS system_profiler.

**Functions:**
- `collect()` â€” Gather all metrics snapshot
- Returns: Dict with ram, swap, cpu, disk, temperature, ollama, chromadb

### token_telemetry.py

#### TokenTelemetry class
Primary token tracking & cost analysis.

**Methods:**
- `get_monthly_stats()` â€” Maandelijkse token stats (totaal, per provider, per model, budget)
- `get_provider_models()` â€” Lijst modellen per provider
- `calculate_cost()` â€” Cost calculation per model

#### TokenTimelineAnalyzer class
Per-model timeline breakdown.

**Methods:**
- `get_daily_model_tokens(year, month)` â€” Dagelijks per model
- `get_weekly_model_tokens(year, month)` â€” Wekelijks per model
- `get_monthly_model_tokens(months_back)` â€” Maandelijks trend

**Helper:**
- `format_token_timeline_section()` â€” Geformateerde output voor rapport

### server_status.py
Main orchestrator. Combineert alle data in unified rapport.

**Functions:**
- `generate_unified_report()` â€” Samenstelt server + tokens + timeline
- `main()` â€” CLI entry point

## Monitoring Strategy

### Token Budget
- Default: â‚¬100/month per provider
- Configurable per provider/model
- Forecasting: extrapolatie naar maand-einde

### RAM Management
- Warning: 70% RAM used
- Critical: 90% RAM used
- Swap: 80% warns, 90% critical alert

### System Health
- Status indicator: HEALTHY / CAUTION / CRITICAL
- Color-coded output (emojis)
- Actionable recommendations

## Data Sources

### Metrics
- `psutil.virtual_memory()` â€” RAM/Swap
- `psutil.cpu_times()` â€” CPU load
- `psutil.disk_usage()` â€” Disk space
- `system_profiler` â€” Temperature (macOS)
- Ollama JSON-RPC API â€” Model info
- ChromaDB direct query â€” Doc counts

### Tokens
- Local database: `token_usage.db` (software-architect skill)
- SQL queries for aggregation:
  - `model_calls` table (timestamp, model, provider, tokens, cost)
  - Group by date/week/month for timeline

## Security

- âœ… API keys in `.env` (not in git)
- âœ… Sensitive data masked in Telegram messages
- âœ… Local computation only (no external APIs for metrics)
- âœ… Database encryption ready (future)

## Troubleshooting

### "Database not found"
```bash
# Check token_usage.db location
ls -la /Users/bonzen/.openclaw/skills/software-architect/token_usage.db

# Update db_path in scripts/server_status.py if needed
```

### "Ollama connection error"
```bash
# Check Ollama is running
ollama serve

# Check endpoint in config
curl http://127.0.0.1:11434/api/tags
```

### "Telegram not sending"
```bash
# Verify chat ID in config
# Check message queue: ls -la /tmp/openclaw_messages/

# Send manual test
python3 scripts/server_status.py --now
```

### "Memory calculation off"
```bash
# Verify metrics collection
python3 -c "from lib.metrics_collector import MetricsCollector; m = MetricsCollector(); print(m.collect()['ram'])"
```

## Contributing

Issues & PRs welcome! Please:
1. Keep code in Dutch (docstrings, comments)
2. Type hints on all functions
3. Error handling comprehensive
4. Test before push

## License

MIT â€” See LICENSE file

## Support

- **Docs:** https://docs.openclaw.ai/
- **Issues:** https://github.com/bonzen-nl/oc-server-status/issues
- **Discord:** https://discord.com/invite/clawd

---

**Version:** 1.3.0 (Unified Report)  
**Last Updated:** 2026-02-27  
**Author:** Mavy (OpenClaw Agent)
