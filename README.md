# Server Status â€” OpenClaw Skill

**Gedetailleerde server health monitoring met autonoom rapportage.**

Verzamelt RAM, CPU, Ollama, ChromaDB, API-kosten metrics en genereert intelligent Nederlandse analyses. Real-time Telegram alerts bij issues.

---

## ðŸŽ¯ Wat doet Server Status?

Server Status is een **comprehensive health monitoring systeem** dat:

- **Metric Collection** â€” RAM, CPU, Swap, Disk, Temperature, Ollama, ChromaDB, API costs
- **Analysis** â€” Mistral analyzeert metrics in context
- **Rapportage** â€” Genereer 100-word Dutch summaries + knelpunten
- **Automated Alerts** â€” Every 6 hours OR immediately on critical thresholds
- **Cost Tracking** â€” Integreert API-spend data
- **Message Queueing** â€” Reliable Telegram delivery via queue

### ðŸ”„ Monitoring Cycle

```
Every 6 hours (+ critical triggers):
    â†“
Collect metrics (psutil, system_profiler, Ollama, ChromaDB)
    â†“
Aggregate JSON
    â†“
Mistral analysis (local, no cloud API)
    â†“
Generate Dutch report (max 100 words)
    â†“
Queue to Telegram message queue
    â†“
Heartbeat processor sends Telegram
    â†“
Bob receives report + metrics
```

---

## ðŸ“¦ Afhankelijkheden

### Systeemvereisten
- **Python:** 3.8+
- **macOS:** system_profiler (for CPU/Temp)
- **Ollama:** Running (optional, for model metrics)
- **ChromaDB:** Path to database (optional)

### Python Dependencies

```
psutil>=5.9.0                 # System metrics
requests>=2.28.0              # Ollama API
python-dotenv>=0.20.0         # .env loading
pyyaml>=6.0                   # Config parsing
```

### External Services (optional)
- Telegram bot (for alerts)
- OpenAI/Gemini APIs (for cost tracking)

---

## âš¡ Quickstart

### 1. Installatie

```bash
# Clone repository
git clone https://github.com/bonzen-nl/oc-server-status
cd oc-server-status

# Virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Dependencies
pip install -r requirements.txt
```

### 2. Configuratie

```bash
# Copy template
cp .env.example .env

# Instellingen:
# TELEGRAM_CHAT_ID=your_chat_id
# OLLAMA_BASE_URL=http://127.0.0.1:11434
# CHROMADB_PATH=/path/to/chromadb
# REPORT_INTERVAL_HOURS=6
```

### 3. Setup LaunchAgent (Auto-start macOS)

```bash
# One-time setup
python3 scripts/install_launchagent.py

# Verify
launchctl list | grep server-status

# View logs
tail -f /tmp/server_status.log
```

### 4. Test Report

```bash
# Generate report immediately (don't wait 6 hours)
python3 scripts/server_status.py --now

# Output: Full report with all metrics
```

---

## ðŸš€ Gebruik

### Manual Reports

```bash
# Immediate status report
python3 scripts/server_status.py --now

# Verbose output (with all details)
python3 scripts/server_status.py --now --verbose

# JSON format (for parsing)
python3 scripts/server_status.py --now --format json > /tmp/status.json
```

### Automatic Monitoring

Once LaunchAgent installed, runs automatically:

```bash
# Check if running
ps aux | grep server_status

# View latest report logs
tail -20 /tmp/server_status.log
```

### Report Content Example

```
ðŸ“Š Server Status â€” 2026-02-27 22:00 CET

System Health: âš ï¸ CAUTION
RAM: 72.5% (7.9GB / 10.9GB) â€” Approaching threshold
CPU: Load 2.3 (4 cores) â€” Normal
Swap: 58.2% (4.1GB / 7.0GB) â€” Healthy

Ollama Models: 2 active
  â€¢ mistral-small3.1:24b (5.2GB)
  â€¢ nomic-embed-text (1.3GB)

ChromaDB: 99 documents indexed
  â€¢ Size: 2.5MB
  â€¢ Last access: 2m ago

API Costs (Month):
  â€¢ Claude: â‚¬12.50 (3,200 tokens)
  â€¢ Gemini: â‚¬3.20 (estimated)
  â€¢ Total: â‚¬15.70 / â‚¬50 budget

âš ï¸ Knelpunten:
- RAM approaching 75% threshold
- Recommend: Close Safari/Chrome to free 2-3GB
- Consider: Unload Mistral if not in use

âœ… System Status: OPERATIONAL
```

---

## ðŸ—ï¸ Projectstructuur

```
oc-server-status/
â”œâ”€â”€ SKILL.md                          # Skill documentatie
â”œâ”€â”€ README.md                         # Dit bestand
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ .env.example                      # Configuration template
â”œâ”€â”€ .gitignore                        # Git security
â”œâ”€â”€ LICENSE                           # MIT
â”œâ”€â”€ config/
â”‚   â””â”€â”€ server_status.json            # Report settings
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ server_status.py              # Main monitor
â”‚   â”œâ”€â”€ metrics_collector.py          # System metrics
â”‚   â”œâ”€â”€ install_launchagent.py        # macOS setup
â”‚   â””â”€â”€ cost_tracker.py               # API costs
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ analyzer.py                   # Mistral analysis
â”‚   â”œâ”€â”€ reporter.py                   # Report generation
â”‚   â”œâ”€â”€ notifier.py                   # Telegram queue
â”‚   â””â”€â”€ metrics.py                    # Collection logic
â””â”€â”€ .venv/                            # Virtual environment
```

---

## ðŸ“Š Collected Metrics

### System Metrics
- **RAM:** Total, used, available (GB + %)
- **Swap:** Total, used (GB + %)
- **CPU:** Load averages (1min, 5min, 15min)
- **Disk:** Free space per volume
- **Temperature:** M-chip temperature (if available)

### Service Metrics
- **Ollama:** Running models, tokens/sec, memory usage
- **ChromaDB:** Document count, database size
- **System Load:** CPU percentage, process count

### Cost Metrics
- **Claude (Anthropic):** Monthly spend + tokens
- **Gemini (Google):** Estimated spend
- **OpenAI:** If configured
- **Total:** Budget vs. spent

---

## ðŸ” Veiligheid

### Environment Variables
- TELEGRAM_CHAT_ID â€” Safely stored in .env
- API keys (optional) â€” Never logged
- Metrics â€” Contain no sensitive data

### Data Retention
- Reports queued in `/tmp/openclaw_messages/`
- Processed & deleted after send
- Logs in `/tmp/server_status.log` (safe to share)

---

## ðŸ§ª Testing

### Unit Tests

```bash
# Test metrics collection
python3 -m pytest tests/test_metrics.py -v

# Test report generation
python3 -m pytest tests/test_reporter.py

# Test message queue
python3 -m pytest tests/test_notifier.py
```

### Manual Tests

```bash
# Dry-run (show report, don't send)
python3 scripts/server_status.py --now --dry-run

# Test Telegram connectivity
python3 scripts/test_telegram.py
```

---

## ðŸ› Troubleshooting

### LaunchAgent Not Running
```bash
# Check status
launchctl list | grep server-status

# Restart service
launchctl stop nl.openclaw.server-status
launchctl start nl.openclaw.server-status

# Debug
log stream --predicate 'process == "server_status"'
```

### Missing Metrics
- Ollama not running? â†’ Install via `brew install ollama`
- ChromaDB path wrong? â†’ Check in .env
- Telegram failing? â†’ Verify bot token

### Reports Not Sending
- Check message queue: `ls -la /tmp/openclaw_messages/`
- Verify Telegram chat ID in .env
- Test: `python3 scripts/test_telegram.py`

---

## ðŸ”— Sub-Projecten & Integraties

Server Status is onderdeel van het **OpenClaw Skills Ecosystem**:

### Master Hub
- **[oc-overzicht](https://github.com/bonzen-nl/oc-overzicht)** â€” Central index

### Gerelateerde Skills
- **[oc-software-architect](https://github.com/bonzen-nl/oc-software-architect)** â€” Receives cost metrics
- **[oc-ram-guardian](https://github.com/bonzen-nl/oc-ram-guardian)** â€” Complementary monitoring
- **[oc-openclaw-expert](https://github.com/bonzen-nl/oc-openclaw-expert)** â€” Monitored service
- **[oc-github-manager](https://github.com/bonzen-nl/oc-github-manager)** â€” Can log issues

### Integration Points

**Software-Architect consults status:**
```python
status = architect.get_system_status()
if status['ram_percent'] > 80:
    task.defer()  # Wait for system to stabilize
```

**GitHub Manager logs critical events:**
```python
if status['critical_alert']:
    github_mgr.create_issue(
        title="ðŸš¨ Critical system event",
        description=status['report']
    )
```

---

## ðŸ“ˆ Performance Metrics

- **Collection overhead:** ~2-3% CPU
- **Analysis (Mistral):** ~7-8 sec, local only
- **Report generation:** ~1 sec
- **Total cycle:** <15 seconds
- **Memory footprint:** ~50MB

---

## ðŸ“ Licentie

MIT Â© 2026 Bonzen

---

## ðŸ“¬ Ondersteuning

- **Issues:** [oc-server-status/issues](https://github.com/bonzen-nl/oc-server-status/issues)
- **Integration:** Zie [oc-software-architect](https://github.com/bonzen-nl/oc-software-architect)

---

**Onderdeel van:** [OpenClaw Skills Suite](https://github.com/bonzen-nl/oc-overzicht)

---

## ðŸ’° Token Telemetry Integration (v1.1.0)

**NEW:** Volledige token-tracking en cost-analyse in status-reports!

OpenClaw Server Status bevat nu gedetailleerde token-verbruik analytics. Elke status-rapport toont:

### Token Overview
- Totaal tokens (input + output)
- Totaal kosten (EUR)
- Breakdown per aanbieder (Anthropic, OpenAI, Gemini, Ollama)
- Per-model kostening
- Per-project tracking
- Monthly budget remaining

### Module Details

**`lib/token_telemetry.py`** â€” Token tracking engine
- Reads from software-architect's token_usage.db
- Calculates costs per provider/model
- Supports monthly, daily, project-level reporting
- Budget alerts & tracking
- Full Dutch documentation + inline comments

**`lib/metrics_collector.py`** â€” System metrics collector
- RAM, CPU, Disk, Temperature monitoring
- Ollama service metrics
- ChromaDB statistics
- Complete with docstrings & type hints

**`scripts/server_status.py`** â€” Main orchestrator
- Combines metrics + token telemetry
- Generates unified Dutch report
- Supports text/JSON output
- CLI interface (--now, --verbose, --format)

### Example Output

```
ðŸ’° TOKEN TELEMETRIE (2026-02):
  Totaal Tokens:        125,450
  Totaal Kosten:        â‚¬15.70

  Per aanbieder:
    anthropic   : â‚¬12.50 (  95,000 tokens)
      â€¢ claude-3-5-sonnet: â‚¬12.50
    openai      :  â‚¬2.80 (  23,450 tokens)
      â€¢ gpt-4o-mini: â‚¬2.80
    gemini      :  â‚¬0.40 (   7,000 tokens)
    ollama      :  â‚¬0.00 (   0 tokens)

  Budget Remaining: â‚¬84.30
```

### Usage

```bash
# Generate full report with token telemetry
python3 scripts/server_status.py --now

# JSON output
python3 scripts/server_status.py --now --format json

# Verbose details
python3 scripts/server_status.py --now --verbose
```

### Files Added
- `lib/token_telemetry.py` â€” Token analytics (350+ lines, fully documented)
- `lib/metrics_collector.py` â€” System metrics (280+ lines, fully documented)
- `scripts/server_status.py` â€” Main script (220+ lines, fully documented)
- `config/server_status.json` â€” Configuration
- `requirements.txt` â€” Dependencies
- `README_TOKEN_TELEMETRY.md` â€” Integration details

### Testing
All modules have been tested and verified:
âœ… Metrics collection
âœ… Token database queries
âœ… Report generation
âœ… Full server status with token telemetry

### Documentatie
- Alle Python modules: Nederlandse docstrings + inline comments
- Type hints op alle functies
- Exception handling voor robustness
- Complete integration documentation

See `README_TOKEN_TELEMETRY.md` for detailed technical documentation.

